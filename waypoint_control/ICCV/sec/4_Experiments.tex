\section{Experiments}

We conducted the following experiments: 
(a) 3D object detection using PointPillars deep learning for LiDAR, 
(b) performing multi-target tracking under single-intersection and multi-intersection scenarios, 
(c) vehicle re-identification between intersections using a ReID network, and 
(d) implementing trajectory digital twins in Carla.

\subsection{preparation}

\begin{table*}[t] 
	\centering
	\caption{Multi-objective tracking evaluation indicators}
	\label{tab:example}
	\begin{tabular}{cccccccccccc}
		\toprule
		Scene & Intersection & Rcll & Prcn & FTR & FP & FN & IDS & MT & ML & MOTA & MOTP\\
		\midrule
		town01 & 1 & 30.1025 & 59.9258 & 0.5106 & 216 & 750 & 18 & 0 & 37.5000 & 8.2945 & 79.9222\\
		& 2 & 64.8065 & 61.5385 & 1.0297 & 450 & 391 & 21 & 55.5556 & 33.3333 & 22.4122 & 86.7746\\
		& 3 & 63.2135 & 45.4407 & 1.1887 & 359 & 174 & 15 & 0 & 25 & -15.8562 & 86.9053\\
		& 4 & 65.8206 & 96.7662 & 0.0369 & 13 & 202 & 20 & 40 & 20 & 60.2369 & 89.0919\\
		& 5 & 41.4035 & 90.0763 & 0.0580 & 13 & 167 & 10 & 50 & 0 & 33.3333 & 88.2471\\
		\hline
		town10 & 1 & 30.6653 & 59.7166 & 0.7960 & 398 & 1334 & 28 & 8.3333 & 50 & 8.5239 & 84.6488\\
		& 2 & 56.4410 & 70.6095 & 1.1380 & 569 & 1055 & 29 & 13.3333 & 26.6667 & 31.7506 & 81.0920\\
		& 3 & 51.9805 & 75.6714 & 0.6160 & 308 & 885 & 17 & 14.2857 & 35.7143 & 34.3462 & 84.2826\\
		& 4 & 52.1930 & 86.1427 & 0.2680 & 134 & 763 & 50 & 27.2727 & 36.3636 & 40.6642 & 88.6035\\
		& 5 & 45.4243 & 62.2719 & 1.6540 & 827 & 1640 & 35 & 12.5000 & 37.5000 & 16.7388 & 86.0825\\
		\bottomrule
	\end{tabular}
\end{table*}

\textbf{Simulation Environment.}
We conducted simulation experiments in Carla, whose advantage lies in its provision of a highly realistic virtual environment capable of accurately simulating complex traffic scenarios and diverse driving conditions. 
Carla supports flexible sensor configurations, such as cameras and LiDAR, facilitating multimodal data acquisition and fusion experiments\cite{Alpher22e}. 
We selected Town10 and Town01 in Carla as our simulation scenarios, which offer the benefit of providing highly realistic and diverse virtual environments, enabling precise simulation and replication of real traffic scenarios. 
The complex urban structure and dense traffic flow of Town10 can simulate highly dynamic real traffic environments, while the simple layout and clear rules of Town1 make it easy to construct controlled experimental scenarios.

\textbf{Data Collection.}
In CARLA's Town10 scenario, a single intersection location is selected, with a LiDAR placed at the center and six cameras arranged around it to achieve 360-degree omnidirectional perception coverage. 
This setup allows for the acquisition of rich point cloud data and image information, making it suitable for target recognition and tracking in complex traffic environments. 
By configuring the LiDAR with 64 channels, a detection range of 100 meters, 250,000 points per second, and a rotation frequency of 20 Hz, the radar can efficiently generate high-density and accurate point cloud data. 
Additionally, one camera is placed at the front and rear of the vehicle, and one camera is positioned on each of the four roads to the left and right. 
The cameras have a resolution of 1920x1080 pixels and a field of view of 90 degrees, ensuring the capture of wide-angle image data in high definition. 
The collected data includes point cloud data from the LiDAR and image data from the cameras. 
The radar data is saved as MAT files with timestamps, while the camera data is saved as images for each frame in six directions. 
The data structure follows the storage format of the Panda dataset, making the data more standardized for subsequent processing and fusion\cite{Alpher21c}. 
Each frame of radar data stores information such as point cloud objects, timestamps, positions relative to the ego vehicle, and detected 3D bounding boxes. 
Each frame of camera data stores image data from six directions, positions relative to the ego vehicle, timestamps, and detected 2D bounding boxes.

\subsection{Experimental effect}

\textbf{Multi-target Tracking.}
Table 2 presents the multi-object tracking performance metrics across different scenarios (town01 and town10) and intersections (Intersection 1-5). 
The data reveals significant variations in performance across different intersections. 
In town01, Intersection 4 shows better performance in terms of Recall (65.8206) and Precision (96.7662), while Intersection 3 has a higher False Track Ratio (1.1887), indicating a greater proportion of incorrect tracking. 
In town10, Intersection 4 also demonstrates relatively high Recall (52.1930) and Precision (86.1427), but Intersection 5 has significantly higher False Positives (827) and False Negatives (1640) compared to other intersections, suggesting a higher number of misidentified and missed targets.

Identity Switches (IDS) are notably higher in Intersection 4 of both town01 and town10, with values of 20 and 50 respectively, indicating more frequent target identity switches at these intersections. 
The Mostly Tracked (MT) and Mostly Lost (ML) metrics show that Intersection 2 in town01 has a higher MT (55.5556), while Intersection 1 in town10 has a higher ML (50), reflecting significant differences in tracking stability across these intersections.

Overall, the MOTA (Multiple Object Tracking Accuracy) and MOTP (Multiple Object Tracking Precision) metrics indicate that Intersection 4 in town01 performs well with MOTA (60.2369) and MOTP (89.0919), whereas Intersection 5 in town10 has a lower MOTA (16.7388), suggesting poorer overall tracking accuracy. 
These data highlight the performance variations of the multi-object tracking system across different scenarios and intersections, providing valuable insights for further optimization.

\textbf{Twin.}
The performance of the digital twin is primarily reflected by two sets of metrics: trajectory metrics, and error and latency metrics (as shown in Tables 3 and 4). 
These two tables compare the performance evaluation metrics of the digital twin in two scenarios, Town01 and Town10. 
The trajectory overlap rate (TOR) in Town01 (50.21\%) is significantly higher than that in Town10 (10.89\%), indicating superior path-tracking capability, possibly due to a simpler environment or more stable control algorithms. 
In terms of mean position error (MPE), the two are close (Town01: 79.58m, Town10: 82.41m). 
However, the maximum position error (MaxPE: 105.89m) and final position error (FPE: 105.09m) in Town10 far exceed those in Town01 (MaxPE: 33.14m, FPE: 19.90m), revealing severe localization deviations in extreme cases, likely caused by complex environments or dynamic obstacles. 
For mean lateral error (MLE) and mean longitudinal error (MLOE), Town10 performs slightly better (MLE: 1.98 vs. 2.19, MLOE: 0.26 vs. 0.53), suggesting more precise lateral and longitudinal control, though overall stability is lacking. 
In terms of mean delay (MD), Town01 (1.20 seconds) outperforms Town10 (1.38 seconds), demonstrating higher task execution efficiency.


\begin{table}[t]
	\centering
	\caption{Table of the trajectory indicator}
	\label{tab:improved}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		\multicolumn{1}{|c|}{Scene} & \multicolumn{1}{c|}{TOR(\%)} & \multicolumn{1}{c|}{MPE(m)} & \multicolumn{1}{c|}{MaxPE(m)} & \multicolumn{1}{c|}{FPE(m)} \\
		\hline
		Town01 & 50.21 & 79.5798 & 33.1382 & 19.8970 \\
		\hline
		Town10 & 10.89 & 82.4108 & 105.8893 & 105.0854 \\
		\hline
	\end{tabular}
\end{table}

\begin{table}[t]
	\centering
	\caption{Table of the error and delay indicators}
	\label{tab:improved}
	\begin{tabular}{|c|c|c|c|}
		\hline
		\multicolumn{1}{|c|}{Scene} & \multicolumn{1}{c|}{MLE} & \multicolumn{1}{c|}{MLOE} & \multicolumn{1}{c|}{MD(s)} \\
		\hline
		Town01 & 2.1889 & 0.5345 & 1.2015 \\
		\hline
		Town10 & 1.9835 & 0.2614 & 1.3780 \\
		\hline
	\end{tabular}
\end{table}

\subsection{Details Explanation}

We conducted ablation studies on radar detection and multi-intersection multi-target tracking in object detection to ensure that our experiments achieved the desired results.

\textbf{Lidar Detection.}
During radar detection, we established a threshold for the detection results: targets exceeding the threshold were identified as vehicles, while those below the threshold were excluded as other objects. 
We conducted three experiments with thresholds set at 0.4, 0.5, and 0.6, respectively. 
The best results were achieved with a threshold of 0.5, which not only maximized the identification of vehicles but also effectively filtered out other clutter. 
At a threshold of 0.4, some non-vehicle objects, such as large containers and barrels, were mistakenly identified as vehicles, and in some cases, cargo loaded on vehicles was even misclassified as a separate vehicle, significantly reducing recognition accuracy. 
Conversely, a threshold of 0.6 led to the missed detection of some vehicles, such as smaller cars, which were occasionally misclassified as boxes and overlooked.

\textbf{Multi Intersection and Multi-target Tracking.}
In the multi-intersection multi-target tracking experiment, the most critical task is the re-identification of vehicles across different intersections. 
Therefore, we also set a threshold for the re-identification results: if the similarity score exceeds the threshold, the targets are considered the same vehicle; otherwise, they are deemed different vehicles. 
During the experiment, we adjusted the threshold multiple times, testing values of 0.6, 0.65, 0.7, 0.8, and 0.9. 
Ultimately, we found that a threshold of 0.65 yielded the best re-identification performance. 
When the threshold was set higher than 0.65, some vehicles failed to match across intersections, and the higher the threshold, the more vehicles were unable to be successfully matched. 
Conversely, when the threshold was set lower than 0.65, it led to incorrect matches for some vehicles.

\subsection{Parameter Optimization}

\textbf{Background and Objectives.}
In order to further improve the performance of the tracker highly depends with the hyperparameter setting. 
Traditional manual parameter tuning is inefficient and difficult to find the global optimal solution. 
For this reason, we adopt a Bayesian Optimization (BOM) approach to automatically optimize the following key parameters through an intelligent search strategy:

$\bullet$ DetectionProbability: control the reliability of sensor detection.

$\bullet$ ClutterDensity: sensitivity to filtering false detections.

$\bullet$ NewTargetDensity: threshold for target initialization.

$\bullet$ Confirmation/DeletionThreshold: trajectory lifecycle management.

$\bullet$ DeathRate: robustness to handling targets leaving the scene.

Optimization Goal: Maximize Tracking Accuracy (MOTA) while reducing ID Switches and Trajectory Fragmentation.

\textbf{Optimize Processes.}
Bayesian optimization is a hyper-parametric optimization method based on probabilistic models, which solves the global optimization problem of black-box functions by the strategy of “finding the best parameter with the least number of attempts”.The process is as follows:1.Maximizing tracking performance by fitting existing data with a Gaussian process and constructing an objective function model in a 6-dimensional parameter space; 
2.A small number of random parameter combinations are selected to calculate the value of the acquisition function, and the next parameter to be tested is selected (e.g., the point with the largest EI); 
3.Run the experiment to get the MOTA corresponding to the new parameters, add to the dataset, and repeat until the maximum number of iterations is reached or convergence is achieved.

\subsection{Limitations and Future Directions}

\textbf{Problems Encountered in The Experiment.}
During our experiments, we encountered the following issues:  
1.When matching trajectories across multiple intersections, images of vehicles corresponding to each trajectory are needed to extract re-identification appearance features. 
Acquiring these images is difficult, and the methods used can affect accuracy.  
2.When matching trajectories, it is necessary to associate trajectories from all intersections. 
However, due to ID switching, the trajectory of the same vehicle at a single intersection may be fragmented, making integration complex. 
If only one trajectory is selected as the current intersection's trajectory for a vehicle, issues arise when the same vehicle returns to the intersection.

\textbf{Shortcomings of Current Research.}
Although our experiments have achieved some success, there are still some limitations. 
For example, the detection accuracy of PointPillars is not high, resulting in suboptimal tracking performance. 
Additionally, false detections may occur when acquiring images of vehicles corresponding to current trajectories, potentially leading to trajectory matching errors.

\textbf{Vision of The Future.}
Our experiments were conducted under offline conditions, meaning they lacked real-time capabilities. 
In future work, we aim to transition these experiments to an online framework to achieve high real-time performance, thereby enhancing their experimental value.